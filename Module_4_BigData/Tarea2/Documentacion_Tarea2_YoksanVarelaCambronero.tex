\documentclass[a4paper]{article}

\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[top=1.25in, bottom=1.25in, left=1in, right=1in]{geometry}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{minted}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{Python}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\begin{document}
\begin{center}
\large{TAREA 2 - YAML Y CREACI\'{O}N DE CSV - BIG DATA}\\
\small{Estudiante: Yoksan Varela Cambronero}\\
\small{27 de Junio, 2024}
\end{center}

\section{Contenido del archivo comprimido}
Dentro del archivo comprimido se encuentran, adem\'{a}s de este documento, los siguientes elementos:
\begin{enumerate}
    \item \textbf{Folder datasets:} Contiene los cinco archivos YAML solicitados en la secci\'{o}n "Datos de Entrada" del enunciado de la tarea 2. Estos fueron creados usando ChatGPT y con algunos ajustes manuales, usando como referencia el ejemplo provisto en el instructivo de la tarea.

    Cada uno de estos archivos hace referencia a una caja registradora distinta, con al menos 10 compras y con una variedad de productos de supermercado. Para efectos de esta tarea, los archivos no cuenta informaci\'{o}n incompleta en las secciones requeridas. Por efecto de tiempo, no se pudo realizar la parte opcional de la tarea, por lo tanto, estos son todos los archivos YAML a ser usados en la ejecuci\'{o}n de la tarea.
    
    \item \textbf{Folder library:} Este folder contiene 4 archivos de Python que contienen todas funciones utilizadas a lo largos del c\'{o}digo MAIN. En la secci\'{o}n \textit{Funciones y sus respectivas Prueba Unitarias} de este documento se explica con m\'{a}s detalle las funciones y las pruebas unitarias asociadas a las mismas. 
    
    \item \textbf{Folder unitary\_tests:} De firma an\'{a}loga al folder anterior, en este se almacenan todas las pruebas unitarias para las funciones mencionadas anteriormente. Para m\'{a}s informaci\'{o}n detallada sobre estas funciones, referirse a la secci\'{o}n \textit{Funciones y sus respectivas Prueba Unitarias}.

    \item \textbf{Folder Results:} Este folder no existe dentro del archivo comprimido, pero ser\'{a} generado por el c\'{o}digo MAIN a la hora de su ejecuci\'{o}n. Este va a contener los archivos CSV solicitados en la tarea, pero podr\'{i}an estar corruptos. Para mayor detalle, ver nota importante en el primer punto en la secci\'{o}n \textit{Decisiones de dise\~{n}o de la soluci\'{o}n}.
    
    \item \textbf{Archivo Big Data - Tarea 2.pdf:} Enunciado de la tarea provisto por el profesor.
    
    \item \textbf{Archivo build\_run\_docker.bat:} Este documento fue creado para facilitar la creaci\'{o}n y la ejecuci\'{o}n del contenedor de Docker en mi computadora personal, la cual cuenta con el OS Windows 11. Internamente, este archivo tiene las siguentes l\'{i}neas: \textit{ docker build --tag tarea2\_yoksanvarela .} y \textit{ docker run -i -t tarea2\_yoksanvarela /bin/bash}.
    
    \item \textbf{Archivo command\_list.txt:} Es un archivo plano de texto que contiene las l\'{i}neas necesarias para poder correr el programa principal y las pruebas unitarias. Cabe la pena rescatar que estos comandos hay que correrlos de forma manual en la consola del contenedor de Docker, y son los mismos comandos que se citan en la secci\'{o}n \textit{Ejecuci\'{o}n del MAIN y las Pruebas Unitarias}.
    
    \item \textbf{Archivo Dockerfile:} Es la imagen usada en Docker, la cual cuenta con cambios con respecto a la usada en la tarea 1. Los cambios son:

    \begin{enumerate}
        \item La inclusi\'{o}n de \textit{apk add build-base} y \textit{python3 -m ensurepip}. Estas fueron necesarias para poder instalar Numpy. Inicialmente se ten\'{i}a planeado usar funciones de Numpy para calcular los percentiles, pero al final se decidi\'{o} usar un proceso m\'{a}s manual para esa secci\'{o}n. 
        \item Adem\'{a}s, se incluy\'{o} \textit{pyyaml y numpy} en la l\'{i}nea de instalacion con pip3. Pyyaml es la libreria seleccionada para transformar los archivos YAML en objectos tipo diccionario que fueron procesados posteriormente para ser convertidos en Spark dataframes.
    \end{enumerate}
    
    \item \textbf{Archivo tarea2\_program\_YoksanVarela.py:} Es el programa principal donde se resuelve el problema planteado en la tarea 1.
    
\end{enumerate}

\section{Decisiones de dise\~{n}o de la soluci\'{o}n}
A continuaci\'{o}n se listan las decisiones de dise\~{n}o tomadas para el desarrollo de esta soluci\'{o}n:

\begin{enumerate}
    \item \textbf{La funci\'{o}n para lectura de los archivos YAML (dentro de yaml\_parser.py), cambio de nombre de los archivos CSV (dentro de tarea2\_program\_YoksanVarela.py) y manejo de los argumentos a la hora de llamar el c\'{o}digo principal (args\_parser.py) NO tienen pruebas unitarias:} Esto se debe a que la funci\'{o}n de estas funciones es vital para que el c\'{o}digo principal se pueda ejecutar o no, adem\'{a}s de la dificultad de probarlas con elementos de memoria en lugar de archivos reales. Es por eso que el hecho que programa principal pueda ejecutarse es, en s\'{i}, la prueba a esta funciones.

    \textbf{Nota importante con respecto a la funci\'{o}n de cambio de nombre de los CSV generados por Spark:} Esta es una funci\'{o}n definida dentro del c\'{o}digo MAIN. Como la funci\'{o}n de creaci\'{o}n de archivos CSV de Spark (.coalesce(1).write.csv() para generar solo un archivo CSV por dataframe) crea los archivos con nombres especiales que permiten un mejor manejo a la hora de almacenaje o lectura distribuida, fue necesario crear esta funci\'{o}n para poder cambiarle el nombre a esos archivos y dejarlos como se solicita en el enunciado. Cuando esta funci\'{o}n ya mencionada se utiliza es probable que el archivo copia generado de los originales quede corrupto y su contenido sea solo basura. Es por este problema que se decidi\'{o} hacer un copia con el nombre correcto dentro del folder Results, pero se mantienen los folders temporales con los archivos originales. Estos son:
    \begin{enumerate}
        \item Si el archivo \textbf{total\_productos.csv} est\'{a} corrupto, revisar el archivo que empieza con la palabra \textit{part-} dentro de \textbf{./Results/tmp\_prod\_total}
        \item Si el archivo \textbf{total\_cajas.csv} est\'{a} corrupto, revisar el archivo que empieza con la palabra \textit{part-} dentro de \textbf{./Results/tmp\_cashier\_total}
        \item Si el archivo \textbf{metricas.csv} est\'{a} corrupto, revisar el archivo que empieza con la palabra \textit{part-} dentro de \textbf{./Results/tmp\_metrics}
    \end{enumerate}

    \item \textbf{L\'{i}neas con NaN or NULL en el Spark dataframe principal (creado con la contatenaci\'{o}n de cada dataframe por cada archivo YAML) de entrada son removidos antes de la ejecuci\'{o}n del resto de funciones:} Se consider\'{o} que el objectivo de esta tarea no era lidiar con esos elementos, lo cual implica que todas las funciones de apoyo usadas en esta tarea no cuentan con l\'{o}gica para lidiar con NaN NULL (esto ya fue probado en la tarea 1). No obstante, las funciones s\'{i} cuentan con manenjo de errores en el caso de faltar informaci\'{o}n importante, l\'{o}gica que s\'{i} es probada en las pruebas unitarias.
    
    \item \textbf{El uso del ingl\'{e}s en todos los c\'{o}digos:} Aunque parezca trivial, considero importante mencionar esta decisi\'{o}n. De forma personal, me siento m\'{a}s c\'{o}modo programando en ingl\'{e}s (incluyendo comentarios, markdowns, etc.) dada mi experiencia laboral, adem\'{a}s de poder hacer c\'{o}digos legibles de manera universal.

    Esta pr\'{a}ctica podr\'{i}a dar pie a pensar que esta soluci\'{o}n podr\'{i}a ser un plagio o que fue desarrollada por otra persona, pero hago constar que el total de esta entrega fue desarrollado por mi persona.
\end{enumerate}

\section{Ejecuci\'{o}n del MAIN y las Pruebas Unitarias}
Estos son los pasos para poder ejecutar tanto el c\'{o}digo principal como las pruebas unitarias:
\begin{enumerate}
    \item Construir el contenedor:
    \begin{lstlisting}[language=Python]
    docker build --tag tarea2_yoksanvarela .
    \end{lstlisting}
        
    \item Correr el contenedor:
    \begin{lstlisting}[language=Python]
    docker run -i -t tarea2_yoksanvarela /bin/bash
    \end{lstlisting}

    \item Correr las pruebas unitarias: En la consola del contenedor, ejecutar los siguientes comandos:
    \begin{lstlisting}[language=Python]
    pytest unitary_tests/test_yaml_parser.py
    pytest unitary_tests/test_data_transformation.py
    pytest unitary_tests/test_data_metrics.py
    \end{lstlisting}

    \item Correr el programa principal: En la consola del contenedor, ejecutar el siguiente comando (es una sola l\'{i}ne):
    \begin{lstlisting}[language=Python]
    spark-submit tarea2_program_YoksanVarela.py ./datasets
    \end{lstlisting}

    \item Revisar los archivos CSV generador por el c\'{o}digo: Revisar los archivos en el folder \textit{Results} creado luego de la ejecuci\'{o}n del programa principal.

\end{enumerate}

\section{Funciones y sus respectivas Prueba Unitarias}
Las funciones usadas a lo largo del programa principal est\'{a}n contenidas en 5 archivos dentro de la carpeta \textit{library}. Las pruebas unitarias est\'{a}n contenidas en 3 archivos dentro de la carpeta \textit{unitary\_tests}. A continuaci\'{o}n se explican todas las funciones:

\begin{itemize}
    \item \textbf{Funci\'{o}n en args\_parser.py:}
        \begin{itemize}
            \item \textbf{Funci\'{o}n:} yaml\_files\_loader()
            \item \textbf{Descripci\'{o}n:} Se encarga de procesar el argumento que se pasa a la hora de ejecutar el c\'{o}digo principal, el directorio donde est\'{a}n almacenados los archivos YAML. A la salida de esta funci\'{o}n se retornan el directorio en s\'{i} y un arreglo de Python que contiene todos los nombres de los archivos YAML encontrados en el directorio.
            \item \textbf{Pruebas Unitarias:} Ninguna.
        \end{itemize}

    \item \textbf{Funci\'{o}n en yaml\_parser.py:}
        \begin{itemize}
            \item \textbf{Funci\'{o}n:} yaml\_file\_parser(yaml\_file)
            \item \textbf{Descripci\'{o}n:} Recibe un archivo YAML y retorna un objeto YAML que es, escencialmente, un diccionario de Python.
            \item \textbf{Pruebas Unitarias:} Ninguna.
        \end{itemize}
        
        \begin{itemize}
            \item \textbf{Funci\'{o}n:} yaml\_to\_spark\_df(yaml\_data)
            \item \textbf{Descripci\'{o}n:} Esta funci\'{o} va a tomar un objecto YAML y convertirlo en un Spark dataframe. La forma en la que lo hace es desempacando el diccionario de forma manual, y usando unos contadores para llevar la cantidad de compras y productos por caja registradora. Al final se retorna un dataframe con las siguientes columnas: \textit{Numero\_Caja}, \textit{Numero\_Compra}, \textit{Numero\_Producto}, \textit{Nombre}, \textit{Cantidad} y \textit{Precio}, o bien, se retorna un FAIL de no poder realizarse este proceso.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_yaml\_parser.py:
                \begin{itemize}
                    \item \textbf{test\_create\_spark\_df(spark\_session):} Usando un YAML string se ejercita la creaci\'{o}n de un Spark dataframe.
                    \item \textbf{test\_no\_numero\_caja(spark\_session):} Prueba el modo de fallo al faltar el n\'{u}mero de caja.
                    \item \textbf{test\_no\_all\_sections(spark\_session):} Prueba el modo de fallo al faltar alguna de las secciones requeridas durante el desempacado.
                \end{itemize}
        \end{itemize}

    \item \textbf{Funciones en data\_metrics.py:}
        \begin{itemize}
            \item \textbf{Funci\'{o}n:} max\_min\_sell(dataframe)
            \item \textbf{Descripci\'{o}n:} Retorna los n\'{u}meros de las cajas registradoras donde se vendi\'{o} m\'{a}s y menos, respectivamente. Se retorna un FAIL en caso que este proceso no se pueda realizar.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_metrics.py:
                \begin{itemize}
                    \item \textbf{test\_max\_values(spark\_session):} Verifica el retorno de las caja con mayor ventas y con menor ventas.
                    \item \textbf{test\_max\_values\_missing\_column(spark\_session):} Verifica el modo de fallo cuando alguna de las columns importantes para el c\'{a}lculo no est\'{a} presente.
                \end{itemize}
        \end{itemize}

        \begin{itemize}
            \item \textbf{Funci\'{o}n:} most\_sold\_product(dataframe)
            \item \textbf{Descripci\'{o}n:} Retorna cual el producto que m\'{a}s se vendi\'{o} entre todas las cajas. Se retorna un FAIL en caso que este proceso no se pueda realizar.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_metrics.py:
                \begin{itemize}
                    \item \textbf{test\_most\_sold\_product(spark\_session):} Verifica el retorno del producto que m\'{a}s se vendi\'{o}.
                    \item \textbf{test\_most\_sold\_product\_missing\_column(spark\_session):} Verifica el modo de fallo cuando alguna de las columns importantes para el c\'{a}lculo no est\'{a} presente.
                \end{itemize}
        \end{itemize}

        \begin{itemize}
            \item \textbf{Funci\'{o}n:} most\_profit\_by\_product(dataframe)
            \item \textbf{Descripci\'{o}n:} Retorna cual el producto que gener\'{o} la mayor cantidad de ganancias o dinero por ventas. Se retorna un FAIL en caso que este proceso no se pueda realizar.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_metrics.py:
                \begin{itemize}
                    \item \textbf{test\_most\_profit(spark\_session):} Verifica el retorno del producto que m\'{a}s ganancias gener\'{o}.
                    \item \textbf{test\_most\_profit\_missing\_column(spark\_session):} Verifica el modo de fallo cuando alguna de las columns importantes para el c\'{a}lculo no est\'{a} presente.
                \end{itemize}
        \end{itemize}

        \begin{itemize}
            \item \textbf{Funci\'{o}n:} percentiles(dataframe)
            \item \textbf{Descripci\'{o}n:} Retorna las ventas puntuales (en dinero) que representan los percentiles 25, 50 y 75. Para hacer este c\'{a}lculo, se eligi\'{o} un proceso en donde se lee la cantidad total de l\'{i}neas del dataframe, se divide es numero en 4 y se convierte al entero m\'{a}s cercano, y luego se retornan los valores de los percentiles de acuerdo a ese \'{i}ndice, de la siguiente forma: percentil 25 es el valor del \'{i}ndice como tal, el 50 es multiplicando ese \'{i}ndice por 2 y el 75 es multiplicando ese \'{i}ndice por 3. Se retornan esos tres valores indexados o bien un FAIL si el proceso no se pudo completar.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_metrics.py:
                \begin{itemize}
                    \item \textbf{test\_percentile\_calculation(spark\_session):} Verifica correcto retorno de los valores que representan los percentiles deseados.
                    \item \textbf{test\_percentile\_calculation\_missing\_column(spark\_session):} Verifica el modo de fallo cuando alguna de las columns importantes para el c\'{a}lculo no est\'{a} presente.
                \end{itemize}
        \end{itemize}

    \item \textbf{Funciones en data\_transformation.py:}
        \begin{itemize}
            \item \textbf{Funci\'{o}n:} dataframe\_union(dataframe1, dataframe2)
            \item \textbf{Descripci\'{o}n:} Aplica un Union entre los dos dataframes en los par\'{a}metros, siempre y cuando ambos dataframes tengan las mismas columnas. El dataframe resultante es retornado, o bien, un estado de FAIL si no es capaz de realizar este proceso debido a que alguna de las columnas importantes no est\'{a} presente.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_transformation.py:
                \begin{itemize}
                    \item \textbf{test\_concatenate\_same\_columns(spark\_session):} Verifica una uni\'{o}n exitosa de dos dataframes con las mismas columnas.
                    \item \textbf{test\_concatenate\_different\_columns(spark\_session):} Prueba la prevenci\'{o}n del caso donde las columnas no son las mismas.
                \end{itemize}
        \end{itemize}

        \begin{itemize}
            \item \textbf{Funci\'{o}n:} product\_count(dataframe)
            \item \textbf{Descripci\'{o}n:} Esta funci\'{o}n hace una agrupaci\'{o}n usando el nombre del producto y agrega la cantidad del producto, generando una columna con la cantidad total vendida del producto entre todas las cajas registradoras. Luego el dataframe se ordena de forma descendente con respecto a la cantidad total calculada y se retorna dicho dataframe. Se retorna FAIL si este proceso no es completado con \'{e}xito.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_transformation.py:
                \begin{itemize}
                    \item \textbf{test\_product\_count\_correct\_sum(spark\_session):} Verifica que el proceso de agrupaci\'{o}n se complete de forma correcta y el c\'{a}lculo la cantidad este bien.
                    \item \textbf{test\_product\_count\_missing\_column(spark\_session):} Verifica el modo de fallo cuando alguna de las columns importantes para el c\'{a}lculo no est\'{a} presente.
                \end{itemize}
        \end{itemize}

        \begin{itemize}
            \item \textbf{Funci\'{o}n:} cashier\_total\_sell(dataframe)
            \item \textbf{Descripci\'{o}n:} Esta funci\'{o}n agrega una columna con el c\'{a}lculo del total vendido (cantidad multiplicado por precio) y luego hace una agrupaci\'{o}n usando el n\'{u}mero de cajas, lo cual provoca una agregaci\'{i}on de la suma de todos los totales vendidos. Al final se ordena el dataframe de form descendiente con respecto al total vendido y se retorna dicho dataframe. Se retorna FAIL si este proceso no es completado con \'{e}xito.
            \item \textbf{Pruebas Unitarias:} En el archivo test\_data\_transformation.py:
                \begin{itemize}
                    \item \textbf{test\_cashier\_total\_sell\_correct\_sum(spark\_session):} Verifica que el proceso de agrupaci\'{o}n se complete de forma correcta y el c\'{a}lculo la suma este bien.
                    \item \textbf{test\_cashier\_total\_sell\_missing\_column(spark\_session):} Verifica el modo de fallo cuando alguna de las columns importantes para el c\'{a}lculo no est\'{a} presente.
                \end{itemize}
        \end{itemize}
    
\end{itemize}

\end{document}